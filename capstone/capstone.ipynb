{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Capstone Project - Winonsin Breast Cancer Diagnosis Deep Learning Revisited\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in WBCD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Boston housing dataset\n",
    "headers = [\"ID\",\"CT\",\"UCSize\",\"UCShape\",\"MA\",\"SECSize\",\"BN\",\"BC\",\"NN\",\"Mitoses\",\"Diagnosis\"]\n",
    "data = pd.read_csv('breast-cancer-wisconsin.csv', names = headers)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('?', np.nan)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale dataset to the range of [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = [\"Diagnosis\",\"CT\",\"UCSize\",\"UCShape\",\"MA\",\"SECSize\",\"BN\",\"BC\",\"NN\",\"Mitoses\"]\n",
    "data[numerical] = scaler.fit_transform(data[numerical])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate Labels/Classes from Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = data['Diagnosis']\n",
    "features = data.drop(['ID','Diagnosis'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, diagnosis, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Pandas DataFrame to Numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test  = X_test.values\n",
    "y_test  = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify dataset using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('score = ', 0.95999999999999996)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "# y_predict = rfc.predict(X_test)\n",
    "\n",
    "score = rfc.score(X_test, y_test)\n",
    "print(\"score = \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "#from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 5)                 50        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 6         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 148\n",
      "Trainable params: 148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Define your architecture.\n",
    "model.add(Dense(9, activation='relu', input_dim=9))\n",
    "model.add(Dense(5, activation='relu', input_shape=(9,)))\n",
    "model.add(Dense(1, activation='relu', input_shape=(5,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "524/524 [==============================] - 0s - loss: 0.6132 - acc: 0.7328     \n",
      "Epoch 2/20\n",
      "524/524 [==============================] - 0s - loss: 0.5621 - acc: 0.8817     \n",
      "Epoch 3/20\n",
      "524/524 [==============================] - 0s - loss: 0.5194 - acc: 0.8969     \n",
      "Epoch 4/20\n",
      "524/524 [==============================] - 0s - loss: 0.4887 - acc: 0.9237     \n",
      "Epoch 5/20\n",
      "524/524 [==============================] - 0s - loss: 0.4660 - acc: 0.9313     \n",
      "Epoch 6/20\n",
      "524/524 [==============================] - 0s - loss: 0.4464 - acc: 0.9408     \n",
      "Epoch 7/20\n",
      "524/524 [==============================] - 0s - loss: 0.4286 - acc: 0.9466     \n",
      "Epoch 8/20\n",
      "524/524 [==============================] - 0s - loss: 0.4134 - acc: 0.9485     \n",
      "Epoch 9/20\n",
      "524/524 [==============================] - 0s - loss: 0.3980 - acc: 0.9580     \n",
      "Epoch 10/20\n",
      "524/524 [==============================] - 0s - loss: 0.3841 - acc: 0.9656     \n",
      "Epoch 11/20\n",
      "524/524 [==============================] - 0s - loss: 0.3705 - acc: 0.9676     \n",
      "Epoch 12/20\n",
      "524/524 [==============================] - 0s - loss: 0.3577 - acc: 0.9695     \n",
      "Epoch 13/20\n",
      "524/524 [==============================] - 0s - loss: 0.3461 - acc: 0.9714     \n",
      "Epoch 14/20\n",
      "524/524 [==============================] - 0s - loss: 0.3337 - acc: 0.9714     \n",
      "Epoch 15/20\n",
      "524/524 [==============================] - 0s - loss: 0.3232 - acc: 0.9656     \n",
      "Epoch 16/20\n",
      "524/524 [==============================] - 0s - loss: 0.3126 - acc: 0.9695     \n",
      "Epoch 17/20\n",
      "524/524 [==============================] - 0s - loss: 0.3027 - acc: 0.9695     \n",
      "Epoch 18/20\n",
      "524/524 [==============================] - 0s - loss: 0.2926 - acc: 0.9656     \n",
      "Epoch 19/20\n",
      "524/524 [==============================] - 0s - loss: 0.2835 - acc: 0.9676     \n",
      "Epoch 20/20\n",
      "524/524 [==============================] - 0s - loss: 0.2748 - acc: 0.9714     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121b22250>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10/175 [>.............................] - ETA: 1s('score = ', [0.27476262705666676, 0.97714285509926935])\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=10)\n",
    "print(\"score = \", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
