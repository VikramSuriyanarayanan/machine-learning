{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Capstone Project - Winonsin Breast Cancer Diagnosis Deep Learning Revisited\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in WBCD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  CT  UCSize  UCShape  MA  SECSize  BN  BC  NN  Mitoses  Diagnosis\n",
      "0  1000025   5       1        1   1        2   1   3   1        1          2\n",
      "1  1002945   5       4        4   5        7  10   3   2        1          2\n",
      "2  1015425   3       1        1   1        2   2   3   1        1          2\n",
      "3  1016277   6       8        8   1        3   4   3   7        1          2\n",
      "4  1017023   4       1        1   3        2   1   3   1        1          2\n",
      "5  1017122   8      10       10   8        7  10   9   7        1          4\n",
      "6  1018099   1       1        1   1        2  10   3   1        1          2\n",
      "7  1018561   2       1        2   1        2   1   3   1        1          2\n",
      "8  1033078   2       1        1   1        2   1   1   1        5          2\n",
      "9  1033078   4       2        1   1        2   1   2   1        1          2\n"
     ]
    }
   ],
   "source": [
    "# Load the Boston housing dataset\n",
    "headers = [\"ID\",\"CT\",\"UCSize\",\"UCShape\",\"MA\",\"SECSize\",\"BN\",\"BC\",\"NN\",\"Mitoses\",\"Diagnosis\"]\n",
    "data = pd.read_csv('breast-cancer-wisconsin.csv', names = headers)\n",
    "data = data.reset_index(drop=True)\n",
    "print(data.head(n = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ID  CT  UCSize  UCShape  MA  SECSize  BN  BC  NN  Mitoses  Diagnosis\n",
      "0   1000025   5       1        1   1        2   1   3   1        1          2\n",
      "1   1002945   5       4        4   5        7  10   3   2        1          2\n",
      "2   1015425   3       1        1   1        2   2   3   1        1          2\n",
      "3   1016277   6       8        8   1        3   4   3   7        1          2\n",
      "4   1017023   4       1        1   3        2   1   3   1        1          2\n",
      "5   1017122   8      10       10   8        7  10   9   7        1          4\n",
      "6   1018099   1       1        1   1        2  10   3   1        1          2\n",
      "7   1018561   2       1        2   1        2   1   3   1        1          2\n",
      "8   1033078   2       1        1   1        2   1   1   1        5          2\n",
      "9   1033078   4       2        1   1        2   1   2   1        1          2\n",
      "10  1035283   1       1        1   1        1   1   3   1        1          2\n",
      "11  1036172   2       1        1   1        2   1   2   1        1          2\n",
      "12  1041801   5       3        3   3        2   3   4   4        1          4\n",
      "13  1043999   1       1        1   1        2   3   3   1        1          2\n",
      "14  1044572   8       7        5  10        7   9   5   5        4          4\n",
      "15  1047630   7       4        6   4        6   1   4   3        1          4\n",
      "16  1048672   4       1        1   1        2   1   2   1        1          2\n",
      "17  1049815   4       1        1   1        2   1   3   1        1          2\n",
      "18  1050670  10       7        7   6        4  10   4   1        2          4\n",
      "19  1050718   6       1        1   1        2   1   3   1        1          2\n"
     ]
    }
   ],
   "source": [
    "data = data.replace('?', np.nan)\n",
    "#print(features_with_missing_data)\n",
    "data = data.fillna(0)\n",
    "print(data.head(n = 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale dataset to the range of [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID        CT    UCSize   UCShape        MA   SECSize   BN        BC  \\\n",
      "0  1000025  0.444444  0.000000  0.000000  0.000000  0.111111  0.1  0.222222   \n",
      "1  1002945  0.444444  0.333333  0.333333  0.444444  0.666667  1.0  0.222222   \n",
      "2  1015425  0.222222  0.000000  0.000000  0.000000  0.111111  0.2  0.222222   \n",
      "3  1016277  0.555556  0.777778  0.777778  0.000000  0.222222  0.4  0.222222   \n",
      "4  1017023  0.333333  0.000000  0.000000  0.222222  0.111111  0.1  0.222222   \n",
      "5  1017122  0.777778  1.000000  1.000000  0.777778  0.666667  1.0  0.888889   \n",
      "6  1018099  0.000000  0.000000  0.000000  0.000000  0.111111  1.0  0.222222   \n",
      "7  1018561  0.111111  0.000000  0.111111  0.000000  0.111111  0.1  0.222222   \n",
      "8  1033078  0.111111  0.000000  0.000000  0.000000  0.111111  0.1  0.000000   \n",
      "9  1033078  0.333333  0.111111  0.000000  0.000000  0.111111  0.1  0.111111   \n",
      "\n",
      "         NN   Mitoses  Diagnosis  \n",
      "0  0.000000  0.000000        0.0  \n",
      "1  0.111111  0.000000        0.0  \n",
      "2  0.000000  0.000000        0.0  \n",
      "3  0.666667  0.000000        0.0  \n",
      "4  0.000000  0.000000        0.0  \n",
      "5  0.666667  0.000000        1.0  \n",
      "6  0.000000  0.000000        0.0  \n",
      "7  0.000000  0.000000        0.0  \n",
      "8  0.000000  0.444444        0.0  \n",
      "9  0.000000  0.000000        0.0  \n"
     ]
    }
   ],
   "source": [
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = [\"Diagnosis\",\"CT\",\"UCSize\",\"UCShape\",\"MA\",\"SECSize\",\"BN\",\"BC\",\"NN\",\"Mitoses\"]\n",
    "data[numerical] = scaler.fit_transform(data[numerical])\n",
    "print(data.head(n = 10))\n",
    "\n",
    "# features[numerical] = scaler.fit_transform(features[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "# print(features.head(n = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         CT    UCSize   UCShape        MA   SECSize   BN        BC        NN  \\\n",
      "0  0.444444  0.000000  0.000000  0.000000  0.111111  0.1  0.222222  0.000000   \n",
      "1  0.444444  0.333333  0.333333  0.444444  0.666667  1.0  0.222222  0.111111   \n",
      "2  0.222222  0.000000  0.000000  0.000000  0.111111  0.2  0.222222  0.000000   \n",
      "3  0.555556  0.777778  0.777778  0.000000  0.222222  0.4  0.222222  0.666667   \n",
      "4  0.333333  0.000000  0.000000  0.222222  0.111111  0.1  0.222222  0.000000   \n",
      "5  0.777778  1.000000  1.000000  0.777778  0.666667  1.0  0.888889  0.666667   \n",
      "6  0.000000  0.000000  0.000000  0.000000  0.111111  1.0  0.222222  0.000000   \n",
      "7  0.111111  0.000000  0.111111  0.000000  0.111111  0.1  0.222222  0.000000   \n",
      "8  0.111111  0.000000  0.000000  0.000000  0.111111  0.1  0.000000  0.000000   \n",
      "9  0.333333  0.111111  0.000000  0.000000  0.111111  0.1  0.111111  0.000000   \n",
      "\n",
      "    Mitoses  \n",
      "0  0.000000  \n",
      "1  0.000000  \n",
      "2  0.000000  \n",
      "3  0.000000  \n",
      "4  0.000000  \n",
      "5  0.000000  \n",
      "6  0.000000  \n",
      "7  0.000000  \n",
      "8  0.444444  \n",
      "9  0.000000  \n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    1.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "Name: Diagnosis, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "diagnosis = data['Diagnosis']\n",
    "features = data.drop(['ID','Diagnosis'], axis = 1)\n",
    "print(features.head(n = 10))\n",
    "print(diagnosis.head(n = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split dataset into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Shuffle and split the data into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, diagnosis, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reindex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Pandas DataFrame to Numpy ndarray\n",
    "* just need to convert X_train since X_test, y_train, and y_test are already numpy ndarrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify dataset using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('score = ', 0.95999999999999996)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "# y_predict = rfc.predict(X_test)\n",
    "\n",
    "score = rfc.score(X_test, y_test)\n",
    "print(\"score = \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import utils as np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_68 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 5)                 50        \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 6         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 148\n",
      "Trainable params: 148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Define your architecture.\n",
    "model.add(Dense(9, activation='relu', input_dim=9))\n",
    "model.add(Dense(5, activation='relu', input_shape=(9,)))\n",
    "model.add(Dense(1, activation='relu', input_shape=(5,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# model.add(Dense(1, activation='sigmoid', input_shape=(1,)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train: ', array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.66666667],\n",
      "       [ 1.        ,  1.        ,  1.        , ...,  0.33333333,\n",
      "         1.        ,  1.        ],\n",
      "       [ 0.77777778,  1.        ,  1.        , ...,  1.        ,\n",
      "         1.        ,  1.        ],\n",
      "       ..., \n",
      "       [ 0.77777778,  0.33333333,  0.66666667, ...,  0.22222222,\n",
      "         0.88888889,  0.11111111],\n",
      "       [ 1.        ,  0.77777778,  1.        , ...,  0.44444444,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.33333333,  0.        ,  0.11111111, ...,  0.22222222,\n",
      "         0.        ,  0.        ]]))\n",
      "('y_train: ', 0      0.0\n",
      "1      1.0\n",
      "2      1.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "5      0.0\n",
      "6      0.0\n",
      "7      1.0\n",
      "8      0.0\n",
      "9      0.0\n",
      "10     0.0\n",
      "11     1.0\n",
      "12     0.0\n",
      "13     0.0\n",
      "14     0.0\n",
      "15     0.0\n",
      "16     0.0\n",
      "17     0.0\n",
      "18     0.0\n",
      "19     0.0\n",
      "20     0.0\n",
      "21     0.0\n",
      "22     0.0\n",
      "23     1.0\n",
      "24     1.0\n",
      "25     1.0\n",
      "26     1.0\n",
      "27     1.0\n",
      "28     1.0\n",
      "29     0.0\n",
      "      ... \n",
      "494    0.0\n",
      "495    1.0\n",
      "496    0.0\n",
      "497    0.0\n",
      "498    1.0\n",
      "499    0.0\n",
      "500    1.0\n",
      "501    0.0\n",
      "502    0.0\n",
      "503    1.0\n",
      "504    0.0\n",
      "505    1.0\n",
      "506    0.0\n",
      "507    0.0\n",
      "508    0.0\n",
      "509    1.0\n",
      "510    0.0\n",
      "511    1.0\n",
      "512    0.0\n",
      "513    1.0\n",
      "514    1.0\n",
      "515    1.0\n",
      "516    0.0\n",
      "517    0.0\n",
      "518    1.0\n",
      "519    1.0\n",
      "520    1.0\n",
      "521    1.0\n",
      "522    1.0\n",
      "523    0.0\n",
      "Name: Diagnosis, Length: 524, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: \", X_train)\n",
    "print(\"y_train: \", y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "524/524 [==============================] - 2s - loss: 0.6767 - acc: 0.6489      \n",
      "Epoch 2/20\n",
      "524/524 [==============================] - 0s - loss: 0.6009 - acc: 0.6489     \n",
      "Epoch 3/20\n",
      "524/524 [==============================] - 0s - loss: 0.5288 - acc: 0.6489     \n",
      "Epoch 4/20\n",
      "524/524 [==============================] - 0s - loss: 0.4665 - acc: 0.6489     \n",
      "Epoch 5/20\n",
      "524/524 [==============================] - 0s - loss: 0.4163 - acc: 0.6489     \n",
      "Epoch 6/20\n",
      "524/524 [==============================] - 0s - loss: 0.3763 - acc: 0.6489     \n",
      "Epoch 7/20\n",
      "524/524 [==============================] - 0s - loss: 0.3465 - acc: 0.8893     \n",
      "Epoch 8/20\n",
      "524/524 [==============================] - 0s - loss: 0.3218 - acc: 0.9466     \n",
      "Epoch 9/20\n",
      "524/524 [==============================] - 0s - loss: 0.3030 - acc: 0.9523     \n",
      "Epoch 10/20\n",
      "524/524 [==============================] - 0s - loss: 0.2887 - acc: 0.9542     \n",
      "Epoch 11/20\n",
      "524/524 [==============================] - 0s - loss: 0.2754 - acc: 0.9523     \n",
      "Epoch 12/20\n",
      "524/524 [==============================] - 0s - loss: 0.2631 - acc: 0.9599     \n",
      "Epoch 13/20\n",
      "524/524 [==============================] - 0s - loss: 0.2534 - acc: 0.9618     \n",
      "Epoch 14/20\n",
      "524/524 [==============================] - 0s - loss: 0.2440 - acc: 0.9618     \n",
      "Epoch 15/20\n",
      "524/524 [==============================] - 0s - loss: 0.2357 - acc: 0.9637     \n",
      "Epoch 16/20\n",
      "524/524 [==============================] - 0s - loss: 0.2273 - acc: 0.9676     \n",
      "Epoch 17/20\n",
      "524/524 [==============================] - 0s - loss: 0.2203 - acc: 0.9695     \n",
      "Epoch 18/20\n",
      "524/524 [==============================] - 0s - loss: 0.2139 - acc: 0.9695     \n",
      "Epoch 19/20\n",
      "524/524 [==============================] - 0s - loss: 0.2071 - acc: 0.9695     \n",
      "Epoch 20/20\n",
      "524/524 [==============================] - 0s - loss: 0.2008 - acc: 0.9695     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124ff2d10>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0 1 2 3 4 5 6 7 8 9] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-db2f609409f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/deeplearning/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[1;32m    894\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/deeplearning/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m//anaconda/envs/deeplearning/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1335\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1337\u001b[0;31m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/deeplearning/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/deeplearning/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/deeplearning/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/deeplearning/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[0 1 2 3 4 5 6 7 8 9] not in index'"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
